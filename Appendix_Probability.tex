\chapter{Appendix Probability}

\section*{Probability Basics}
Let $\mu$ be a non-negative countably additive set function over a sigma algebra $\Omega$ of sets from a sample space $S$. In probability theory, $\Omega$ is the set of possible events $E$. Sets of measure zero denote impossible outcomes. An important feature of measures $\nu$ and $\mu$ that agree on sets of measure zero is the ability to define a derivative $\frac{d \nu}{d \mu}$, the Radon-Nikodym derivative.  When $\nu (E)=0 \fall E \in \Omega \;| \; \mu(e)=0$  Alternatively, given a measure $\mu$ and a nonnegative measurable function $f$, a new measure can be defined by $ \nu(E) = \int\limits{E \in \Omega}{} f d \mu$. A random variable is a real valued function on a sample space into a metric space, $X : S \rightarrow \dblr^{1} $. Associated with a random variable is it's probability density function $f_{X}(x)=P(\{s \in S | X(s) = x\})$ operating on an algebra of sets generated by the sample space $S$. By definition, $f_{X}(x)$ is the sum of probabilities of the events in $S$ that get mapped to $x \in \dblr$ by $X$.  Let $\script{B}(S)$ be the Borel sets on $S$, then $X$ has density $f$ if $P(X \in A) = \int_{A \in \script{B}(S)} f(x) dx $ and distribution function $F(x) = P(X<x)=\int\limits_{-\infty}^x f(y) dy$ so $F'(x)=f(x) \;\; a.e.$.  $E(X)=\int x f(x) dx$ is the expectation of $X$.  The characteristic function $\phi(x) = E(e^{itX} )$ determines the distribution and is used in the proof of the CLT theorem, testing for symmetry, and conditional independence.  We denote samples with lower case in this section.  $x_1 \ldots x_n$ is a random sample of size $n$  In $\dblr^n$ the random variate $X$ has distribution function $F(x_i, \ldots , x_n) = P(X_1<x_1, \ldots , X_n<x_n )$ and density $f(x_1, \ldots , x_n )$.

For parametric distributions, one is interested in the question of what value of a parameter best describes the data at hand.  This obviously requires the assumption that the data derives from a family of distributions parameterized by one or more variables $\theta_k$.  If $x_1 \ldots x_n$ is a random sample from $X$ with a distribution given by $p(x;\theta_1 \ldots \theta_k)$, we can think of the joint pdf of of the sample $L(x_i, \ldots,x_n) = \prod\limits_{i=1}^{n} p(x_i;\theta_1 \ldots \theta_k)$ as being explained by the parameters.  $L$ is the likelihood of the data given the parameters.  The maximum likelihood estimate is obtained by solving the set of equations;
\begin{eqnarray} \nonumber
  \frac{\partial L(\theta_1 \ldots \theta_k)}{\partial
  \theta_1}=0 \\ \nonumber
  \vdots \\ \nonumber
   \frac{\partial L(\theta_1 \ldots \theta_k)}{\partial
   \theta_k}=0 \\ \nonumber
\end{eqnarray}

%$ P(X), P(X|Y), P(X,Y) p(x) p_i x_i \mathbf{X} \mathbf{\beta}$

The statistical moments of a random variable $X$ are defined $\mu_n = E [ X^n] = \int_\Omega X^n P(X)dX$.  The characteristic function is the fourier transform of $P(X)$ \[\Phi(\omega)=\digamma \mathcal{F} [P(X)] (\omega) = \int\limits_{\infty}^{\infty} e^{i \omega X} P(X) dX.\]  Taking the logarithm and expanding in a MacLauren series, we can relate the statistical moments to the coefficients. Statistical moments are central or raw.

Common sample descriptive statistics relating to location, scale, tail size,  and peakedness;
\[ mean = \hat{\mu_1} = \frac{1}{n}\sum x_i  \]
\[ variance = sdd^2 =  \hat{\mu_2} = \frac{1}{n-1} \sum (x_i- \hat{\mu_1}\]
\[ skewness = \frac{ \hat{\mu_3}}{\hat{\mu_2}^{3/2}} \]
\[ kurtosis = \frac{\hat{\mu_4}}{\hat{\mu_2}^2} \]
The linear association between $X_i$ and $X_j$ is measured by the covariance \[ Cov_{ij} = \sigma_{ij} = \frac{1}{n-1} \sum_k (x_ki - \hat{\mu_1}_i)(x_{kj} - \hat{\mu_1}_j). \]  For a measure without dependence on units the scaled covariance is the correlation \[C_{ij} =\frac{\sigma_{ij}}{\sqrt{\sigma_{ii}}\sqrt{\sigma_{jj}}}\]

\section*{Univariate Probability Distributions}
This section covers the properties of common univariate
probability distributions.

\subsection{Uniform,  $U(\alpha,\beta)$}
$X=_d U(\alpha,\beta)$ if $p(x; \alpha, \beta)=
\frac{\chi_{[\alpha,\beta]}}{\beta-\alpha}.$

\subsection{Exponential Class of Distributions}
The exponential class of distributions are characterized by the
functional for of the pdf; \[ p(x;\theta) =
exp(\alpha(x)\beta(\theta)+\gamma(\theta)+\delta(x) ) \].  This
class of distributions form the basis of Generalized Linear
Model Theory that is discussed below.

There is an alternate parametrization of the exponential family
that explicitly includes a dispersion parameter $\phi$.  This
is useful for count data where $E[X]=E[X^2]=\theta$  In general
if $E[X^2]>E[X]$ we say the process  or data is over dispersed.
The parameter $\phi$ is usually fixed in practice.  If we write
\[ p(x; \theta, \phi)=exp(\frac{x \theta-
\beta(\theta)}{\alpha(\phi)}+\gamma(x,\phi))\], the dispersion
parameter $\phi$ for some common distributions;
\[
\begin{array}{cc}
p(x;\theta, \phi) & \phi \\ \hline
N(\mu,\sigma) & \sigma^2 \\
IG(\mu,\sigma) & \sigma^2 \\
Gamma(\theta,\phi) & \frac{1}{\phi} \\
Poisson(\theta) & 1 \\
Binomial(\theta) & 1 \\
Negative Binomial(\theta,r) & r \\
\end{array}
\]

\subsubsection{Normal/Gaussian, $N(\mu,\sigma)$}
$X=_d N(\mu,\sigma)$ if \[p(x; \mu, \sigma) = \frac{1}{\sqrt{2
\pi \sigma^2}} exp ( \frac{(x-\mu)^2}{2 \sigma^2}\].  This can
be re-written in exponential form \[ p(x;\theta) = exp( \frac{x
\theta}{2 \sigma^2} - \frac{\theta^2}{2 \sigma^2 }-
\frac{1}{2}log(2 \pi \sigma^2) - \frac{x^2}{2 \sigma^2 } ) \]

\subsubsection{Binomial}
Setting \[\alpha(x)=x \;\;,
\beta(\theta)=log(\frac{\theta}{1-\theta}) \;\;,
\gamma(\theta)=n log(1-\theta) \;\;, \delta(x)=log ( \biggl(
\begin{array}{c}  n \\  y \\ \end{array}  \biggr) )
\] gives us the binomial distribution $p(x;\theta) = \binomial{n}{x} \theta^x
(1-\theta)^{(n-x)}$

\subsubsection{Negative Binomial}
\[p(x;\theta,r)=\binomial{x+r-1}{r-1} \theta^r (1-\theta)^x\]

\subsubsection{Poisson}
$X$ is Poisson distributed if $p(x;\theta)=\frac{\theta^x
e^{-\theta}}{x!}$  Setting $\beta(\theta)=log(\theta) \;\;,
\gamma(\theta)=-\theta \;\;, \delta(x)=-log(x!)$ we get the
exponential form of the Poisson distribution,
\[p(x;\theta)= exp(x log(\theta) - \theta- log(x!))\]

The expected value and the variance of a Poisson distributed random variable is equal to $\theta$. The higher moments of the Poisson distribution are the Touchard polynomials in $\theta$.  There is a combinatorial interpretation.  When $E[X]=1$ for a Poisson random variate then the i-th moment of $X$ is equal to the number of partitions of a set of size n $\frac{1}{e} \sum\limits_{n=0}^{\infty} \frac{n^i}{n!}$ via Dobinski.  The normal distribution with mean $\theta$ and variance $\theta$ is a good approximation to the Poisson distribution for large $\theta$.


\subsubsection{Pareto}
$X$ is Pareto distributed if \[p(x;\theta)=\theta
x^{-\theta}.\]

\subsubsection{Gamma}
$X$ is Gamma distributed if \[p(x;\theta,
\phi)=\frac{x^{\phi^{-1}}\theta^\phi e^{-x \theta}} {
\Gamma(\phi)}.\]

\subsubsection{Weibull}
$X$ follows the Weibull distribution if \[p(x; \theta , \lambda
) = \frac{\lambda x^{\lambda-1}}{\theta^\lambda}
e^{(\frac{x}{\theta} )^\lambda}.\]

\subsubsection{Inverse Gaussian/ Wald Distribution}
$X$ follows the Inverse Gaussian distribution if
\[p(x;\theta)= \sqrt{\frac{\theta}{2 \pi x^3 \sigma}}exp(-
\frac{\lambda(x-\theta)^2}{2 x \theta^2 \sigma}) \]

\subsection{Generalized Extreme Value Distribution $GEV(\theta,\phi,\xi)$}
This class of distributions includes the three limiting extreme
value distributions of \cite{Fisher Tippet (1928)} and
\cite{Gnedenko (1943)}.  $X =_d GEV(\theta,\phi,\xi)$ if
\[p(x;\theta,\phi,\xi)= exp( -  max\biggl(\bigl(1 + \xi
\frac{x-\theta}{\phi} \bigr)^{- \frac{1}{\xi} }, \;\; 0 \biggr)
\]. Where


\subsection{Multinomial}%bbcrevisit explanation
Let \[\Omega=\mathcal{B}(\prod\limits_{i=0}^{i=\infty}
\dblz(K))\] be the Borel Algebra generated by $\prod {1, 2,
\hdots , K}$. This is the sample space of all realizations of
experiments with $K$ categorical outcomes. Equip $\dblz(K)= {i
\in {1, \hdots, K}}$ with a measure $P(i)=\theta_i$. Let
${X_i}$ be n iid copies of $X =_d p(i ; \pi_1, \hdots ,
\pi_K)$.  Now map $\mbf{X}=(X_1, \hdots, X_n) \in \Omega
\rightarrow \mbf{Y} \in \dbln^K$  Then $Y_i$ are counts of the
number of elements of category $i$ in the experiment with n
observations.  The multinomial distribution is given by
\[p(\mbf{Y};n)=\frac{n!}{y_1! \hdots y_K!} (\theta_1)^{y_1} \hdots
(\theta_K)^{y_K} \].  This in not a member of the exponential
family, but we can show that the multinomial distribution is
the joint distribution of ${Y_i =_d Poission(\theta'_i)}_{i=1,
\hdots K}$ random variables conditional to their sum.
\[p(\mbf{Y}; \theta'_1, \hdots , \theta'_K) =
\prod\limits_{i=1}^{K} \frac{ (\theta'_i)^{y_i} \;
e^{-\theta'_i}}{y_i!}\], set $n=Y_1 + \hdots + Y_K$. Writing
$p(\mbf{Y} | n) =p(\mbf{Y}; \theta'_1, \hdots ,
\theta'_K) / p(n)$ and noting that $n=_d Poisson(\sum\limits_{i=1}^{K} \theta'_i)$, %bbcrevisit this is an exercise
we recover the multinomial distribution by simplifying and
setting $\theta_i=\frac{\theta'_i}{\sum\limits_{i=1}^{K}
\theta'_i}$

\subsection{$\chi^2(n)$}
If ${X_i}$ iid $N(0,1)$ and $Y_i=X_i^2$ then
$Y=\sum\limits_{i=1}^{n} Y_i =_d \chi^2(n).$  $E[Y]=n$ and
$Var(Y)=E[(Y-\mu_Y)^2]=E[(Y-E[Y])^2]=2n$. More generally, if
$Y_i=X_i+\mu_i$ then \[Y=\sum\limits_{i=1}^{n} (Y_i)^2 =
\sum\limits_{i=1}^{n} X_i^2 + 2 \sum\limits_{i=1}^{n} X_i \mu_i
+ \sum\limits_{i=1}^{n} \mu_i^2 =_d \chi^2(n,\lambda)\].  Where
$\lambda=\sum\limits_{i=1}^{n} \mu_i$ is non-centrality
parameter.

See the section on multivariate probability distributions for
further information, but it is worth noting that if $X =_d
N(\mu,\sigma)$ is multivariate and the variance covariance
matrix $s\sigma$ is non-singular, then $(y-\mu)^T  \sigma^{-1}
(y-\mu) =_d \chi^2(n)$ and setting $\lambda= \mu^T \sigma^{-1}
\mu$ we have $ y^T \sigma^{-1} y =_d \chi^s(n,\lambda)$

\subsection{Student-t $t(\nu)$}
$X =_d \frac{\Gamma(\frac{\nu+1}{2})}{\sqrt{\pi} \Gamma(\nu
/2)}(1+x^2)^{- \frac{\nu+1}{2}}$

%\cite{C. C. Heyde and N. N. Leonenko 2005}

\subsection{Generalized Inverse Gaussian $GIG(\lambda,\alpha,\beta )$}
The GIG distributions are characterized by\[p(x; \lambda,
\theta,\sigma)=\bigl(\frac{\theta}{\sigma}\bigr)^{\frac{\lambda}{2}}
x^{\lambda-1}\: \frac{1}{2 K_\lambda (\sqrt{\theta \sigma})} \:
exp(-\frac{1}{2} ( \theta x^{-1} + \sigma x) \].

Note,  $GIG(-1/2,\theta,\sigma)=IG(\theta,\sigma)$

The GIG family members arise as first passage time
distributions of ordinary Brownian diffusions to a constant
boundary.

\subsection{ Normalized Inverse Gaussian $NIG(\mu,\alpha,\beta,\delta)$}
$X =_d NIG(\mu,\alpha,\beta,\delta)$ if \[p(x;\mu,
\beta,\alpha,\delta)= \frac{\delta \alpha}{\pi} exp \bigl(
\delta \sqrt{\alpha^2 - \beta^2}+\beta(x-\mu) \bigr)
\frac{K_1(\alpha \; s_\delta(x-\mu))}{s_\delta(x-\mu)}\]

where $x \in \dblr \;\; \mu \in \dblr \;\; \delta>0 \;\; 0 \leq
|\beta| \leq \alpha$ and $s_\delta(x)=\sqrt{\delta^2+x^2}$ and
$K_1(x)=\frac{x}{4} \int\limits_{0}^{\infty} exp - \bigl (
y+\frac{x^2}{4 y} \bigr ) y^{-2} \;dy$ is the modified Bessel
function of the third kind.  This family of distributions is
infinitely divisible, $\exts \;\; X_t$, a Levy process, $ X_{t+
\Delta t} - X_t =_d X_{\Delta t} =_d
NIG(\mu,\alpha,\beta,\delta)$. $X_t$ is a pure jump process,
and
\[p(t; \alpha,\beta,\delta)= \biggl( \frac{\delta \alpha}{\pi |t|}
\biggr) e^{\beta t} K_1(\alpha  |t|)\]. See Eberlein and Keller
(1995) and  Barndorff-Nielsen (1998)


\subsection{Generalized Hyperbolic $GH(\lambda,\alpha,\beta,\delta,\mu)$}
The parameters $\lambda,\alpha,\beta,\delta,\mu$ have the
respective interpretation of tail heaviness, kurtosis,
skewness, and scale, and location.  The distribution includes
the important classes GIG, NIG, IG, and can be characterized as
a Normal variance-mean mixture NVMM parameterized by a GIG
distribution. Formally set $U=_d GIG()$, then $X=_d NVMM( )$ if
$P(X|U=u) =_d N(\mu+ \beta, u \Delta)$.  This gives a
stochastic representation $X= \mu+\beta Z + \sqrt{Z} Y$ where
$Y =_d N(0,1)$ and $Z =_d GIG( )$.

\section*{Limit Theorems}
Limit Theorems use the notion of a basin of attraction for pdf's in some functional space $\mathcal{H}$. In $L^2(\Omega)$, we have $N(\mu,\sigma) \subset L^2(\Omega, \nu)$ is the basin of attraction for all pdf's satisfying the conditions of the CLT.

The CLT says that the series $\frac{\sum\limits_{i=1}^{n} X_i}{n}$ converges in in probability to the mean of $x_i$. Cramer's theorem gives a bound on the probability of large deviation away from the mean in the series $\frac{\sum\limits_{i=1}^{n} X_i}{n}$.  The probability decays exponentially with a rate given by the Legendre transform of the cumulant generating function for $X_i$
\begin{thm}[Cramer's Theorem]
Let $X_1, X_2, \hdots $ be iid $E(X_i)=0$, $E(X_i^2)= \sigma^2$, and $F_n(x) = P(\frac{1}{\sigma n^{\frac{1}{2}}}  \sum\limits_{i=1}^{n} X_i < x)$, then if $x>1$ and $x=O(\sqrt{n})$ as  $n \rightarrow \infty$
we have
\begin{eqnarray*}
  \frac{1-F_n(x)}{1-\Phi(x)} = exp ( \frac{x^3}{\sqrt{n}} \lambda( \frac{x}{\sqrt{n}} )  ) [ 1 + O(\frac{x}{\sqrt{n}}) ]
\end{eqnarray*}

$\lambda(x) = \sum\limits_{i=0}^{\infty} c_i x_i$   where the $c_i$ depend on the moments of $X_i$.
$\Phi(x)$ is the distribution\ function of $N(0,1)$.
\end{thm}

\begin{thm}[Law of Large Numbers]
\end{thm}

The CLT tells us that the pdf of the scaled mean of a sample approaches the normal distribution and the Berry–Esseen theorem specifies the rate at which that happens.  The CLT requires $X_i$ to be iid, and with finite second moment and the Berry-Esseen theorem additionally requires a finite third moment.
\begin{thm}[Berry–Esseen]
Let ${X_i}$ be iid, $E(X_i^2)=\sigma$, $E(X_i^3)=\rho$, $Y_n = \frac{X_1 + \ldots + X_n}{n}$, and $F_n = \int \frac{Y_n \sqrt{n} }{\sigma}$ and $\Phi$ the CDF of $N(0,1)$, then
\begin{equation}
\abs{F_n(x) - \Phi(x)} \leq \frac{C \rho}{ \sigma^3 \sqrt{n} }
\end{equation}

\end{thm}

\section*{Multivariate Probability Distributions}

Let $S_n$ be the unit sphere in $\dblr^n$ A random variate $X$
is uniformly distributed on $S_n$ when $X$ is radially
symmetric and $||X||_{L^2} = 1 a.s.$  The pdf of a radially
symmetric random variable is necessarily of the form
$f(x_1,...,x_n)=g(||x||)$ for some $g \in [0,\infty) \ni
\int\limits_{0}^{\infty} n V_n r^{n-1} g(r) dr =1$ where
$V_n=\frac{\pi^{\frac{d}{2}}}{\Gamma(\frac{d}{2}+1) }$ is the
volume of $S_n$. If $X$ is radially symmetric , then
$\frac{X}{|||X||}$ is uniformly distributed on $S_n$.  If $X$
is uniformly distributed on $S_n$ then $(X_1^2, \ldots ,
X_{n}^{2}) =_{dist} (\frac{Y_1}{\kappa} , \ldots ,
\frac{Y_n}{\kappa} )$ where $Y_i$ iid $\Gamma(\frac{1}{2})$
with sum $\kappa$.  If $N_1, \ldots , N_n$ iid normal, then
$(N_1, \ldots , N_n)$ is radially symmetric with density $g(r)
= \frac{1}{(2 \pi)^{\frac{n}{2} } } e^{\frac{ - r^2}{2}}$  This
leads us to an algorithm for generating pseudo random variants
on uniformly distributed on $S_n$ ;
\begin{itemize}
    \item Generate $n$ iid $N(0,1)$
    \item Compute $ \kappa = ( \sum\limits_i=1^n N_i^2
        )^\frac{1}{2}$
    \item Return $(\frac{N_1}{\kappa} , \ldots ,
        \frac{N_n}{\kappa} )$
\end{itemize}
\cite{Devorye}

With a little linear algebra, the above can be generalized to a
generator for $N(\mu, \Sigma ) \in \dblr^n$.  Consider $f(x)
=\frac{1}{(2 \pi)^{\frac{n}{2} } } e^{ - \frac{1}{2} x^T \dot x
} x \in \dblr_n$, $f$ has density of $n$ iid $N(0,1)$ rv if

\subsection{Multivariate Normal $N(\mbf{\mu},\mbf{\Sigma})$ }
$N(\mbf{\mu},\mbf{\Sigma})$ is arguably the most important and tractable multivariate probability distribution. The Gaussian distribution is separable via rotation.  Precisely the rotation induced by PCA.

\subsection{Wishart Distribution}
The Wishart distribution $W(n)$ is the multivariate generalization of the $\chi^2(n)$ distribution.  If $X_{(i)} \sim N(\mbf{\mu},\mbf{\Sigma})$, then
$X X^t =S \sim W(N)$.

\subsection{Elliptic $E(\mbf{\mu},\mbf{\Sigma})$}
Elliptical distributions $E(\mbf{\mu},\mbf{\Sigma})$ extend the multivariate normal $N(\mbf{\mu},\mbf{\Sigma})$.  They can be characterized as affine maps of spherical distributions. The density functions
are defined by $p(x) = c g(  (x-\mu)' \Sigma^{-1} (x-\mu) )$  Where $g : \dblr^{+} \longrightarrow \dblr^{+}$ and $ \Sigma \succ 0$ is positive definite.
Many of the properties of the multivariate normal distribution
are shared by the elliptical distributions. Linear combinations, marginal distributions and conditional distributions of elliptical random variables can largely be determined by linear algebra using knowledge of covariance
matrix, mean and generator.

\section*{Statistical Dependence}
Linear correlation is a natural dependence measure for
multivariate normally and elliptically distributed random variables.  Other dependence concepts include rank correlation, comonotonicity, and Brownian covariance.


\section*{Distance measures for probability distribution functions.}
A number of distance measures for probability distance
functions exist.  Kullbak Lieber divergence:\[ J_D  =
\int\limits_{\text{x}} {[p({\text{x}}\mid\omega_1 ) -
p({\text{x}}\mid\omega_2 )]}
     \log \frac{{p(x\mid\omega_1 )}} {{p(x\mid\omega_2 )}}{\text{dx}}\]
which simplifies to:\[ J_D  = \tfrac{1} {2}\left( {\mu _2  -
\mu _1 } \right)^T  \left( {\Sigma _1^{^{ - 1} }  + \Sigma
_2^{^{ - 1} } } \right)\left( {\mu _2  - \mu _1 } \right) +
\tfrac{1} {2}{\text{tr}}\left\{ {\Sigma _1^{^{ - 1} } \Sigma _2
+ \Sigma _2^{^{ - 1} } \Sigma _1  - 2I} \right\}\] when \[X_1
=_d N(\mu_1,\Sigma_1) \;\; , \;\; X_2 =_d N(\mu_2,\Sigma_2).\]

The Bhattacharyya distance :
\[J_B  =  - \log \int {\left[ {p(\xi \left| {\omega _1 }
\right.)p(\xi \left| {\omega _2 } \right.)} \right]} ^{{1/2}}
{\text{d}}\xi
\] which simplifies to: \[
J_B  = \tfrac{1} {8}\left( {\mu _2  - \mu _1 } \right)^T \left(
{\frac{{\Sigma _1  + \Sigma _2 }} {2}} \right)^{ - 1} \left(
{\mu _2  - \mu _1 } \right) + \tfrac{1}
{2}{\text{log}}\frac{{\left| {\tfrac{1} {2}(\Sigma _1  + \Sigma
_2 )} \right|}} {{( {\left| {\Sigma _1 } \right|\left| {\Sigma
_2 } \right|} )^{1/2} }}
\] when \[X_1 =_d  N(\mu_1,\Sigma_1) \;\; , \;\; X_2 =_d
N(\mu_2,\Sigma_2).\]

The Matusita distance:
\[J_T  = \left\{ {\int {\left[ {\sqrt {p(\xi \left| {\omega _1 }
\right.)}  - \sqrt {p(\xi \left| {\omega _2 } \right.)} } \right]}
^2 {\text{d}}\xi } \right\}^{{1 / 2}} \] which simplifies to: \[
J_T = \left\{ {2\left[ {1 - \exp ( - J_B )} \right]}
\right\}^{{1/2 }} \] where $J_B$ is the Bhattacharyya distance,
when \[X_1 =_d  N(\mu_1,\Sigma_1) \;\; , \;\; X_2 =_d
N(\mu_2,\Sigma_2).\]

The Patrick-Fisher distance:
\[J_P  = \left\{ {\int {\left[ {p(\xi \left| {\omega _1 }
\right.)P_1  - p(\xi \left| {\omega _2 } \right.)P_2 } \right]} ^2
{\text{d}}\xi } \right\}^{{1/2}}\] which simplifies to:\[J_P =
\begin{array}{cc} {(2\pi )^d \left| {2\Sigma _1 } \right|} )^{ -
{1/2}} + ( {(2\pi )^d \left| {2\Sigma _2 } \right|} )^{ - {1/2}} -
\\ 2( {(2\pi )^d \left| {\Sigma _1  + \Sigma _2 } \right|}
)^{-{1/2}} \exp \left\{ { - \tfrac{1} {2}(\mu _2  - \mu _1
)^T(\Sigma _1  + \Sigma _2 )^{ - 1} (\mu _2  - \mu _1 )}
\right\}\end{array}\] when \[X_1 =_d N(\mu_1,\Sigma_1) \;\;  ,
\;\; X_2 =_d N(\mu_2,\Sigma_2).\]
 Reference: pp257, et sqq., Devijver, P.A.
\& Kittler, J (1982) "Pattern Recognition: A Statistical
Approach", Prentice Hall International, Englewood Cliffs, NJ.

\section*{$S_\alpha(\sigma,\beta,\mu)$ Stable Random Variates}

A Levy process is a stochastic process with a drift, a diffusion, and a jump component.
The Lévy–Khinchine representation of a Levy process $X_t$ with parameters $(a,\sigma^2,W)$
is given by

The Levy-Ito decompositon of a Levy process $X_t$ is a decomposition of $X_t$ into
singular, absolutely continuous, and discrete processes
\begin{eqnarray*}
 X_{ac} : X_{ac} \ll X \\
 X_s : X_s \perp X \\
 X_d : card (supp X_d) = \aleph_0
\end{eqnarray*}
via Lebesgue's decomposition theorem.


\subsection{4 definitions of stable}
\begin{itemize}
    \item If \[\exts C, D \fall A,B s.t. A X_1+BX_2=_dCX+D
        \fall X_1,X_2\] independent copies of $X$, then $X
        \in S_\alpha(\sigma,\beta,\mu)$. Furthermore $\exts
        \alpha \in (0,2] s.t. C$ satisfies
        $C^\alpha=A^\alpha+B^\alpha$, for any stable RV and
        $\fall A,B$
    \item Stable RV's satisfy a general CLT. If \[\fall n
        \geq 2 \exts C_n>0 D_n \in \dblr s.s. X_i+X_@
        \hdots X_n=_D C_n X+D_n\] where ${X_i}$ iid, then
        $X \in S_\alpha(\sigma,\beta,\mu)$
    \item If $\exts \; iid \; RV \;{Y_i}$ and \[{d_n},
        {a_n} \in BBCREVISIT^n \dblr^n s.t
        \frac{\sum\limits_{1}^{n} Y_i}{d_n}+a_n=_d X\] then
        $X \in S_\alpha(\sigma,\beta,\mu)$.
    \item If $\exts \alpha \in (0,2], \; \sigma \geq0 \;
        \beta \in [-1,1], \; \mu \in \dblr$ such that
    \[ E[e^{i \theta X}]=\int_\Omega e^{i \theta X} dX = exp\bigr(
    -\sigma^\alpha |\theta|^\alpha (1-i \beta \;sgn(\theta)\; tan
    \bigl(\frac{\pi \alpha}{2} \bigr) + i \mu \theta)\bigl) \] when $\alpha \neq 1$
    and when $\alpha =1$ we have \[E[e^{i \theta X}]=exp (
    -\sigma |\theta|(1+i \frac{2}{\pi} \beta \; sgn(\theta)
    \; ln|\theta| + i \mu \theta) )\]
\end{itemize}



\subsection{Variance Gamma Process}
$X_{VG}(t;\sigma,\nu,\theta)\theta  \gamma(t;\nu)+\sigma
W_{Y(t;\nu)}$ where $\gamma(t;\nu)$is a $\Gamma$ process.
\[P_{\gamma(t;\nu)}(x)=\frac{  x^{\frac{t}{\nu-1}} e^-\frac{x}{\nu}
} {\nu^{t/ \nu} \Gamma( t/ \nu)}\]  \[\Phi_{VG}(\omega)=E(e^{i
\omega X_{VG}}) = \frac{1}{(1-i \omega \nu \theta + \sigma^2
\nu \mu^2 / 2)^{t / \nu}}\]  We can show that the Variance
Gamma process is the difference of two independent Gamma
processes $ X_{VG}=\gamma_p - \gamma_n$ to obtain a new pdf
\[P_{\gamma(t;\nu)} =\biggl\{\begin{array}{cc} \frac{1}{\nu |x|} e^{-|x| / \eta_p} \;\;\;  x<0 \\
\frac{1}{\nu |x|} e^{-|x| / \eta_n} \;\;\;  x>0
\end{array} \].
%
%\section*{Martingales}
%Martingales are sequences of random variables $\{X_i\}$where
%the conditional expectation of $X_i$ given all the previous
%values is $X_{i-1}$.  \[ E( X_i | X_{i-1} \ldots X_0) = X_{i-1}
%\]  An ergodic stochastic process $X_t$is one where the sample
%moments $m_r = \frac{1}{N} \sum\limits_{i=1}^{N}(x_i- m)^r$
%converge to the population moments $E[X_t^r] = \int X_t^r dP$

\section*{Maximum Entropy}
Entropy in the context of information theory is expressed in units of bits, the amount of uncertainty in a yes or no question. Formally, for a sequence $ \{X_i\} \ni p_i  $ is a priori/posteriori probability of observing $X_i$ we define $H=- \sum\limits_{i} p_i log_2( p_i) $.  We can define the entropy of a probability distribution by $H=\int\limits_{\-infty}^{\infty} p(x) log( p(x) ) dx $.  We see the uniform distribution maximizes the entropy; if $p_i=\alpha \fall i$ then $\frac{\partial H}{\partial } = log p +1/p=0 $

\section*{Gaussian Processes}
$X_t$ is a Gaussian process (GP) if $\forall (t_1,...t_n)$ we have that $(X_{t_1}, ... ,X_{t_n}) \approx N(\mu, \Sigma)$. $\Sigma \sim K(x,x')$ the covariance functions.  Gaussian processes are defined by second order statistics (BBCREVISIT). $K(x,x')$ specifies a distribution on functions (in the distribution sense of functional analysis). Every covariance function is a scalar product of vectors.  Orenstein-Uhlenbeck (OU) and Brownian Motion (BM) are Gaussian processes. If a GP depends on $|x-x'|$ it is stationary.  The OU process is a stationary GP and BM is not. The covariance function of the OU process is not differentiable.  If a Gaussian process depends only on $|x-x'|$ it's called isotropic, these form an important class of
Here we list the common covariance functions (kernels) constant, linear, Gaussian noise, square exponential, and OU.
\begin{center}\begin{eqnarray*}
K_c(x,x')= const \\
K_\script{l}(x,x') = <x,x'> \\
K_{GN}(x,x') = \sigma^2 \delta_{x,x'} \\
K_{SE}(x,x') = e^{ \frac{-|d|^2}{2 \script{l}} }\\
K_{OU}(x,x') = e^{ \frac{-|d|}{\script{l}} }
\end{eqnarray*}\end{center}
Here $\script{l}$ is the length scale and $d = |x-x'|$ 

\section*{Discretizing Continuous Variables}

R discretization library implements Fayyad and Irani

Python https://github.com/navicto/Discretization-MDLPC

Most methods used for discretizing a continuous variable use its relationship
to another variable to determine the partitions. This is often found in
classification procedures, such as decision trees6 ] 10 and in naive Bayesian
classifiers.11,12
An entropy based method, proposed by Fayyad and Irani,6 chooses the
partitioning point s in a sorted set of continuous values to minimize the joint Ž .
entropy Ž Ž .. H X, Y of the continuous variable and the classification variable.
This is applied to the creation of decision tree structures for classification by
66 CLARKE AND BARTON
recursively finding more partitioning points top-down discretization . The Ž .
method is expanded to minimize a MDL metric to choose the partitioning
points.
Another MDL based method for discretization is described by Pfahringer.7
A set of the best partitioning points is determined by recursively partitioning the
Ž D sorted variable values to a depth D 2 y 1 partitions in a binary tree. Then .
the MDL metric is used in a best first search in this set to determine the best
partitions for decision tree classification.
A method that merges adjacent partitions of sorted variable values, according
to the x2 statistical test, is described by Liu and Setiono.8 The variable
values are sorted and initially partitioned into, at most, N intervals. The
intervals are first recursively merged according to the lowest x2 value until a
significance level of 0.05 is reached for each partition. The intervals are further
merged until a preset error rate with the classification variable is reached. If
there is only one resulting interval, the variable is not relevant to the classification
problem and is dropped. This method combines the discretization of
continuous variables with feature selection for classification.
Dougherty, Kohavi, and Sahami9 compared several discretization techniques
with decision trees and with naive Bayesian classifiers. They found that a
MDL metric, similar to that used by Fayyad and Irani,6 provided slightly better
classifications in both methods.
A metric for discretization, based upon a variable’s classification in relation
to other variables, is described by Hong.10 This metric is based upon a K
nearest neighbor clustering technique and is used to generate decision trees. An
interesting feature of this method is that it returns an optimal number of
partitions according to the metric. This is done by finding the ‘‘knee’’ of the
plotted curve of the score as a function of the number of partitions. The plot is a
concave function of the metric; the knee is the point on the plot where the
changes in the number of variable values Ž . X axis become greater than
the changes in the metric value Ž . Y axis . The concavity of a plot is exploited in
the information theoretic discretization methods developed in Section IV.
Subramonian, Venkata, and Chen,13 describe a visual framework for interactive
discretization for decision tree classification. A user can choose between
several algorithms and metrics for a classification problem, instead of being
limited to one method and metric. The choice of metrics includes cross-entropy
and the L y 1 norm between two distributions.
Pazzani11 describes a technique for iterative discretization of continuous
variables for naive Bayesian classifiers. Each continuous variable is initially
divided into five partitions. For each variable, two partitions are then merged or
a partition is divided into two partitions to find a lower classification error. This
procedure is repeated for each continuous variable until the error rate can no
longer be reduced.
Another method for constructing naive Bayesian classifiers using a MDL
metric is presented by Friedman and Goldszmidt.12 This method begins by
finding the best initial partition of a continuous variable by dividing the range
BAYESIAN BELIEF NETWORKS 67
into two partitions and then iterating the partitioning until there is no further
improvement in the MDL score top-down partitioning . The MDL metric Ž .
includes all of the variables used for classification and is repeated for each
continuous variable. Given a BBN structure, this method discretizes each
continuous variable in the Markov blanket of each classification variable. This
procedure is iterated until there is no improvement in each local MDL score.
Friedman and Goldszmidt propose that this method can be adopted to
learning BBN structure by starting with some initial discretization of each
continuous variable, learning an initial structure, and then rediscretizing as
described above. While this technique optimizes the conditional probabilities, it
depends upon the initial approximate discretization of continuous variables to
learn the correct network structure.
Extensions to current discretization techniques for classification methods
have been proposed for BBNs, but none have currently been published. Methods
for both static done in data preprocessing and dynamic done during BBN Ž .Ž
construction discretization of continuous variables are presented in Sections IV .
and V.
Often, a continuous variable has a normal, or Gaussian, frequency distribution.
The characteristics of the normal distribution are well understood and a
unified heuristic method for finding a BBN structure with both discrete variables
and continuous variables with a Gaussian distribution is described by Heckerman
and Geiger.14 This method requires the mean and variance of each
continuous variable’s values to parameterize the distribution